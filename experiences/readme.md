Research
==============

## Conference Proceedings
**Do Large Language Models (LLMs) Understand Chronology?** [[arXiv]](https://arxiv.org/abs/2511.14214), [[code]](https://github.com/kennywong524/chronollm)    
**Wongchamcharoen, P. K.**, & Glasserman, P.  

<details>
<summary><b>[View Abstract]</b></summary>

Large language models have shown great potential as forecasting tools in finance and economics, but backtesting performance is subject to look-ahead bias if the period overlaps with an LLM’s training window. Prompt-based attempts to avoid look-ahead bias require that LLMs understand chronology. We test LLMs’ ability to understand and enforce chronological order in three types of tasks: sorting randomly shuffled historical events; conditional sorting of events defined by some conditions; and anachronism detection based on intersections of multiple timelines. Our experiments use events that we first confirm are known to the LLM; this ensures that we test chronological understanding on an LLM’s pretrained internal knowledge. Across three LLM families— GPT-4.1 (standard), GPT-5 (hybrid-reasoning), and Claude 3.7 Sonnet (large-reasoning, with and without Extended Thinking), we find that performance degrades rapidly with problem complexity but improves greatly for reasoning models with test-time extended reasoning. These patterns are important for the real-time application of LLMs in finance.

</details>

- *Proceedings of the 2026 AAAI Conference on Artificial Intelligence (AAAI-26)*  
 **Oral Presentation** – Student Abstract & Poster Program (**Top 11%**) [[poster]](https://underline.io/events/501/posters/21797/poster/145920-747-do-large-language-models-llms-understand-chronologyquestion-student-abstract?tab=poster), [[talk]](https://underline.io/lecture/138612-do-large-language-models-llms-understand-chronologyquestion-student-abstract)
- Extended paper also accepted at [*AI4TS: AI for Time Series Analysis (AAAI-26 Workshop)*](https://ai4ts.github.io/aaai2026) [[extended paper]](https://github.com/AI4TS/AI4TS.github.io/blob/main/Camera_ready_AAAI2026/10.AAAI_chronollms_AI4TS_camready_withcode.pdf)
- Invited presentation at *Yale Undergraduate Research Conference (YURC 2026)*, *IISE Annual Conference 2026*

## Working Paper & Preprints
**Decoding Human-AI Augmentation: Measuring the Value of LLM Assistance on Professional Tasks Using Simulation**                                                                                                                                                                                                                   **Wongchamcharoen, P. K.**, Gulati, K., Fong, M. M., & Nagaraj, A.

<details>
<summary><b>[View Abstract]</b></summary>

Static LLM leaderboards measure end-to-end task execution, yet many real world deployments rely on centaur workflows where one model provides structured assistance to a human or another model. We investigate whether a model’s direct task-solving ability (”automation”) correlates with its capacity to guide a weaker worker (”augmentation”), proposing an evaluation framework that treats assistance as a distinct capability. Across diverse professional tasks grounded in O\*NET and the Anthropic Economic Index (e.g., operations research, counseling, and creative writing), we compare direct model performance against assistant-to-worker pipelines using a fixed worker (GPT-3.5 Turbo) and varying scaffold models. LLM-based rubric grading reveals that scaffolding reliably improves output structure and usefulness. However, model rankings diverge sharply depending on the task: for open-ended professional tasks, models that are weak standalone solvers often serve as highly effective ”teachers.” Expert human validation confirms the directional benefits of scaffolding but highlights calibration gaps in LLM-as-a-judge scoring, emphasizing the need for robust evaluation protocols. Ultimately, our findings demonstrate that supervisory skill is distinct from direct execution capability and represents an economically meaningful dimension of LLM performance missed by conventional benchmarks.

</details>

- Working Paper, February 2026


## Other Research & Awards
**Data-Driven Evaluation of Board of Directors Effectiveness: Unsupervised Learning and Predictive Modeling of "Skills Matrices"**
**Wongchamcharoen, P. K.**, Stringer, C., Hwang B., Liu, I., & Li, K. [[poster]](https://cdss.berkeley.edu/project/measuring-board-effectiveness)                                   
- *Best Data Visualization Award* at *the 2025 Berkeley CDSS Data Discovery Symposium*

**Mixed-Integer Linear Program for Options Pricing and Portfolio Optimization**                                                                                                          
Bin Abdulla, Q. M., **Wongchamcharoen, P. K.**, Jamari, A., Lee J. [[code]](https://github.com/Qamil-Mirza/badss-2025-options-alpha-strategy/tree/main), [[poster]](https://drive.google.com/file/d/1xZiLPutwOY4EdhwzPEcP0V7GRSoi1qjC/view?usp=sharing)
- *1st Runner-Up* at *the 2025 Wells Fargo & Berkeley IEOR Bay Area Decision Sciences Summit*
- Also presented at *the 2025 Berkeley IEOR Community Celebration & Alumni Achievement Ceremony*

## Contributions as an RA
**Calyber: A Ridesharing Game.**, *INFORMS Transactions on Education*, forthcoming.                                    
Shen, Y., Yan, C. and Yan, J.        
- *Runner-up, 2025 INFORMS Case Competition* [[press]](https://ieor.berkeley.edu/uc-berkeley-ieor-at-the-2025-informs-annual-meeting/)

## Works in Progress
- *Flex or Fast?* Incentive-Compatible Demand Allocation in Destination-Mode Ride-Hailing Networks

Please refer to my [CV](https://kennywong524.github.io/files/Kenny_CV_2026_updated.pdf) for more detailed and complete research assistantships & publications.

# Professional Experiences

Please refer to my [resume](https://drive.google.com/file/d/1OvByTf_bYpJS-wfEsPA8PVdvtgcyBM4z/view?usp=drive_link) for more recent industry experiences.
